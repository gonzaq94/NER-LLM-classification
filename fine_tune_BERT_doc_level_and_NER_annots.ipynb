{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMtacIzGntX2D99j6A3Y3nC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gonzaq94/NER-LLM-classification/blob/main/fine_tune_BERT_doc_level_and_NER_annots.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfLms2TWYnow"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPxYOY1wYrmQ",
        "outputId": "db010faf-c1a5-4638-d3b2-311b28db6dc9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install comet_ml\n",
        "!pip install comet_llm\n",
        "!pip install openai\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCSNV2zX8_5z",
        "outputId": "6a6a0d2e-6614-416f-d50a-f142b9a014dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: comet_ml in /usr/local/lib/python3.10/dist-packages (3.47.1)\n",
            "Requirement already satisfied: everett<3.2.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet_ml) (3.1.0)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (4.23.0)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (5.9.5)\n",
            "Requirement already satisfied: python-box<7.0.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (6.1.0)\n",
            "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.32.3)\n",
            "Requirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.10.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.17.0)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.10/dist-packages (from comet_ml) (3.19.3)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.2.3)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.16.0)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (3.1.1)\n",
            "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (0.22.4)\n",
            "Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (13.9.3)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet_ml) (5.0.9)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n",
            "Requirement already satisfied: comet_llm in /usr/local/lib/python3.10/dist-packages (2.2.7)\n",
            "Requirement already satisfied: comet-ml>=3.43.0 in /usr/local/lib/python3.10/dist-packages (from comet_llm) (3.47.1)\n",
            "Requirement already satisfied: flatten-dict in /usr/local/lib/python3.10/dist-packages (from comet_llm) (0.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from comet_llm) (2.32.3)\n",
            "Requirement already satisfied: types-requests in /usr/local/lib/python3.10/dist-packages (from comet_llm) (2.32.0.20241016)\n",
            "Requirement already satisfied: everett<3.2.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml>=3.43.0->comet_llm) (3.1.0)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml>=3.43.0->comet_llm) (4.23.0)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet-ml>=3.43.0->comet_llm) (5.9.5)\n",
            "Requirement already satisfied: python-box<7.0.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml>=3.43.0->comet_llm) (6.1.0)\n",
            "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml>=3.43.0->comet_llm) (1.0.0)\n",
            "Requirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml>=3.43.0->comet_llm) (2.10.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml>=3.43.0->comet_llm) (2.17.0)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.10/dist-packages (from comet-ml>=3.43.0->comet_llm) (3.19.3)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet-ml>=3.43.0->comet_llm) (2.2.3)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml>=3.43.0->comet_llm) (1.16.0)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml>=3.43.0->comet_llm) (3.1.1)\n",
            "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /usr/local/lib/python3.10/dist-packages (from comet-ml>=3.43.0->comet_llm) (0.22.4)\n",
            "Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml>=3.43.0->comet_llm) (13.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->comet_llm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->comet_llm) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->comet_llm) (2024.8.30)\n",
            "Requirement already satisfied: six<2.0,>=1.12 in /usr/local/lib/python3.10/dist-packages (from flatten-dict->comet_llm) (1.16.0)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml>=3.43.0->comet_llm) (5.0.9)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml>=3.43.0->comet_llm) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml>=3.43.0->comet_llm) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml>=3.43.0->comet_llm) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml>=3.43.0->comet_llm) (0.20.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml>=3.43.0->comet_llm) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml>=3.43.0->comet_llm) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml>=3.43.0->comet_llm) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet-ml>=3.43.0->comet_llm) (0.1.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import comet_ml\n",
        "import comet_llm\n",
        "import os\n",
        "import gdown\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "import random\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, TrainerCallback\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from openai import OpenAI\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from torch.nn import CrossEntropyLoss, MSELoss"
      ],
      "metadata": {
        "id": "aGcKHyewYzcq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Data preparation"
      ],
      "metadata": {
        "id": "Scx1gDBH99Uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_from_disk\n",
        "\n",
        "loaded_train_dataset = load_from_disk(\"/content/drive/My Drive/Colab Notebooks/conll2003_train_augmented_1k_strat\")\n",
        "loaded_valid_dataset = load_from_disk(\"/content/drive/My Drive/Colab Notebooks/conll2003_valid_augmented_1k_strat\")\n",
        "loaded_test_dataset = load_from_disk(\"/content/drive/My Drive/Colab Notebooks/conll2003_test_augmented\")"
      ],
      "metadata": {
        "id": "Yy9gFeRj9_kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log results and assets to Comet\n",
        "os.environ[\"COMET_LOG_ASSETS\"] = \"True\"\n",
        "os.environ[\"COMET_WORKSPACE\"] = \"gonzaq94\"\n",
        "os.environ[\"COMET_PROJECT_NAME\"] = \"ner_classif-bert-doc_level_and_NER_annots-strat_data\""
      ],
      "metadata": {
        "id": "7QBoCOIN-IlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "class SeqTokenDataset(Dataset):\n",
        "    def __init__(self, texts, token_labels, sequence_labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.token_labels = token_labels\n",
        "        self.sequence_labels = sequence_labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        token_labels = self.token_labels[idx]\n",
        "        sequence_labels = self.sequence_labels[idx]\n",
        "\n",
        "        tokens = []\n",
        "        labels_per_token = []\n",
        "        attention_masks = []\n",
        "\n",
        "        # first add the CLS special token\n",
        "        tokens.append(self.tokenizer.cls_token_id)\n",
        "        labels_per_token.append(-100)\n",
        "        attention_masks.append(0)\n",
        "\n",
        "        # tokenize each word independantly\n",
        "        for word, label in zip(text, token_labels):\n",
        "          # Tokenize each word\n",
        "          word_encoding = self.tokenizer(\n",
        "              word,\n",
        "              add_special_tokens=False,\n",
        "              max_length=self.max_length,\n",
        "              truncation=True,\n",
        "              return_tensors=\"pt\"\n",
        "          )\n",
        "\n",
        "          tokens.extend(word_encoding['input_ids'][0].tolist())\n",
        "          attention_masks.extend(word_encoding['attention_mask'][0].tolist())\n",
        "          labels_per_token.extend([label] * len(word_encoding['input_ids'][0]))\n",
        "\n",
        "        # finally, add the SEP special token\n",
        "        tokens.append(self.tokenizer.sep_token_id)\n",
        "        labels_per_token.append(-100)\n",
        "        attention_masks.append(0)\n",
        "\n",
        "        # add padding\n",
        "        padding_len = self.max_length - len(tokens)\n",
        "        tokens += [0] * padding_len\n",
        "        attention_masks += [0] * padding_len\n",
        "        labels_per_token += [-100] * padding_len\n",
        "\n",
        "        return {\n",
        "            'input_ids': torch.tensor(tokens).flatten(),\n",
        "            'attention_mask': torch.tensor(attention_masks).flatten(),\n",
        "            'token_labels': torch.tensor(labels_per_token).flatten(),\n",
        "            'sequence_labels': torch.tensor(sequence_labels).flatten()\n",
        "        }"
      ],
      "metadata": {
        "id": "IBHr5FPeVjf_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a8832ba-a78d-4e02-cd11-fc68c7c79191"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_train_dataset = loaded_train_dataset.shuffle()\n",
        "\n",
        "train_custom_dataset = SeqTokenDataset(\n",
        "    texts=loaded_train_dataset['tokens'],\n",
        "    token_labels=loaded_train_dataset['ner_tags'],\n",
        "    sequence_labels=loaded_train_dataset['doc_labels'],\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=256\n",
        ")\n",
        "\n",
        "valid_custom_dataset = SeqTokenDataset(\n",
        "    texts=loaded_valid_dataset['tokens'],\n",
        "    token_labels=loaded_valid_dataset['ner_tags'],\n",
        "    sequence_labels=loaded_valid_dataset['doc_labels'],\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=256\n",
        ")\n",
        "\n",
        "test_custom_dataset = SeqTokenDataset(\n",
        "    texts=loaded_test_dataset['tokens'],\n",
        "    token_labels=loaded_test_dataset['ner_tags'],\n",
        "    sequence_labels=loaded_test_dataset['doc_labels'],\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=256\n",
        ")"
      ],
      "metadata": {
        "id": "oHGiDOEgV1MZ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Sequence and token classification model"
      ],
      "metadata": {
        "id": "KrjQd4LeAtvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertPreTrainedModel, BertModel, BertConfig\n",
        "import torch.nn as nn\n",
        "\n",
        "class CustomBertConfig(BertConfig):\n",
        "    def __init__(self, num_token_labels = 10, num_sequence_labels = 2, seq_loss_weight = 1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_token_labels = num_token_labels\n",
        "        self.num_sequence_labels = num_sequence_labels\n",
        "        self.seq_loss_weight = seq_loss_weight\n",
        "\n",
        "class BertForSequenceAndTokenClassification(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels_sequence = config.num_sequence_labels\n",
        "        self.num_labels_token = config.num_token_labels\n",
        "        self.seq_loss_weight = config.seq_loss_weight\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.token_classifier = nn.Linear(config.hidden_size, self.num_labels_sequence)\n",
        "        self.sequence_classifier = nn.Linear(config.hidden_size, self.num_labels_token)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        token_labels=None,\n",
        "        sequence_labels=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "    ):\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "        )\n",
        "\n",
        "        # token classification\n",
        "        token_representation = self.dropout(outputs.last_hidden_state)\n",
        "        token_logits = self.token_classifier(token_representation)\n",
        "\n",
        "        # sequence classification\n",
        "        sequence_representation = self.dropout(outputs.pooler_output)\n",
        "        sequence_logits = self.sequence_classifier(sequence_representation)\n",
        "\n",
        "        outputs = (token_logits,) + (sequence_logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "\n",
        "        # token loss\n",
        "        if token_labels is not None or sequence_labels is not None:\n",
        "          if token_labels is not None:\n",
        "              loss_fct = CrossEntropyLoss()\n",
        "\n",
        "              if attention_mask is not None:\n",
        "                  active_token_loss = attention_mask.view(-1) == 1\n",
        "                  active_token_logits = token_logits.view(-1, self.num_labels_token)\n",
        "                  active_labels_token = torch.where(\n",
        "                      active_token_loss, token_labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(token_labels)\n",
        "                  )\n",
        "                  token_loss = loss_fct(active_token_logits, active_labels_token)\n",
        "              else:\n",
        "                  token_loss = loss_fct(token_logits.view(-1, self.num_labels_token), token_labels.view(-1))\n",
        "          else:\n",
        "            token_loss = 0.0\n",
        "\n",
        "          # sequence loss\n",
        "          if sequence_labels is not None:\n",
        "            if self.num_labels_sequence == 1:\n",
        "                #  We are doing regression\n",
        "                loss_fct = MSELoss()\n",
        "                sequence_loss = loss_fct(sequence_logits.view(-1), sequence_labels.view(-1))\n",
        "            else:\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                sequence_loss = loss_fct(sequence_logits.view(-1, self.num_labels_sequence), sequence_labels.view(-1))\n",
        "          else:\n",
        "            sequence_loss = 0.0\n",
        "\n",
        "          total_loss = (1 - self.seq_loss_weight) * token_loss + self.seq_loss_weight * sequence_loss\n",
        "\n",
        "          outputs = (total_loss,) + outputs\n",
        "\n",
        "        return outputs  # (loss), token_logits, sequence_logits, (hidden_states), (attentions)\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, pretrained_model_name_or_path, num_token_labels, num_sequence_labels, seq_loss_weight=1, *args, **kwargs):\n",
        "\n",
        "        # load config\n",
        "        config = CustomBertConfig.from_pretrained(pretrained_model_name_or_path, *args, **kwargs)\n",
        "        config.num_token_labels = num_token_labels\n",
        "        config.num_sequence_labels = num_sequence_labels\n",
        "        config.seq_loss_weight = seq_loss_weight\n",
        "\n",
        "        # create model instance\n",
        "        model = cls(config)\n",
        "\n",
        "        # load BERT pre-trained weights\n",
        "        model.bert = BertModel.from_pretrained(pretrained_model_name_or_path)\n",
        "\n",
        "        return model\n",
        "\n"
      ],
      "metadata": {
        "id": "Lli7KYb4Ax3G"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_label_dct = {\"World\": 0, \"Sport\": 1, \"Business\": 2, \"Technology\": 3, \"Other\": 4}\n",
        "ner_label_dct = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
        "\n",
        "\n",
        "model_name = 'bert-base-uncased'\n",
        "model = BertForSequenceAndTokenClassification.from_pretrained(model_name,\n",
        "                                                           num_sequence_labels=len(doc_label_dct),\n",
        "                                                           num_token_labels=len(ner_label_dct),\n",
        "                                                           seq_loss_weight=1,\n",
        "                                                           attention_probs_dropout_prob=0.0,\n",
        "                                                           hidden_dropout_prob=0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27jWqQ5r-LMe",
        "outputId": "2b022e5d-db9e-4863-ee8d-9bd7eefe69dd"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
            "Model config CustomBertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_sequence_labels\": 2,\n",
            "  \"num_token_labels\": 10,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"seq_loss_weight\": 1,\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/model.safetensors\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = predictions.argmax(-1)  # Get the predicted class indices\n",
        "    true_predictions = [p for (p, l) in zip(predictions.flatten(), labels.flatten()) if l != -100]\n",
        "    true_labels = [l for l in labels.flatten() if l != -100]\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, true_predictions, average='weighted', zero_division=1 )\n",
        "    acc = accuracy_score(true_labels, true_predictions)\n",
        "\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "metadata": {
        "id": "V4_dj9hV-mnt"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_freqs = torch.tensor(np.histogram(loaded_train_dataset['doc_labels'], bins=5)[0]).to(\"cuda\")\n",
        "class_weights = 1.0 / class_freqs\n",
        "class_weights = class_weights / class_weights.sum()\n",
        "print(class_weights, class_freqs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0TupMG5H1lK",
        "outputId": "6e5f1855-634d-4ddd-a63e-41a56035567d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1638, 0.0662, 0.1502, 0.5709, 0.0490]) tensor([122, 302, 133,  35, 408])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "\n",
        "# weighted loss\n",
        "class WeightedTrainer(Trainer):\n",
        "  def compute_loss(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
        "      labels = inputs.get(\"labels\")\n",
        "      outputs = model(**inputs)\n",
        "      logits = outputs.get(\"logits\")\n",
        "\n",
        "      loss_fct = CrossEntropyLoss(weight=class_weights)\n",
        "      loss = loss_fct(logits.view(-1, len(class_weights)), labels.view(-1))\n",
        "\n",
        "      return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "\n",
        "# weighted data loader\n",
        "sampler = WeightedRandomSampler(weights=class_weights, num_samples=len(class_weights), replacement=True)\n",
        "\n",
        "def torch_weighted_data_collator(features):\n",
        "\n",
        "    # Sample features with weights according to their label\n",
        "    labels = [f[\"label\"] for f in features]\n",
        "    weights = [class_weights[label] for label in labels]\n",
        "    total_weight = sum(weights)\n",
        "    probabilities = [weight / total_weight for weight in weights]\n",
        "\n",
        "    # Sample with probabilities\n",
        "    features = random.choices(features, weights=probabilities, k=len(features))\n",
        "\n",
        "    batch = {}\n",
        "\n",
        "    # Convert features to tensors\n",
        "    for k in features[0].keys():\n",
        "        if k == 'label':\n",
        "            newk = 'labels'\n",
        "        else:\n",
        "            newk = k\n",
        "        if isinstance(features[0][k], torch.Tensor):\n",
        "            batch[newk] = torch.stack([f[k] for f in features])  # Use stack for tensors\n",
        "        else:\n",
        "            batch[newk] = torch.tensor([f[k] for f in features])  # Convert to tensor\n",
        "\n",
        "    return batch\n",
        "\n",
        "def torch_default_data_collator(features):\n",
        "\n",
        "    first = features[0]\n",
        "    batch = {}\n",
        "\n",
        "    # Special handling for labels.\n",
        "    # Ensure that tensor is created with the correct type\n",
        "    # (it should be automatically the case, but let's make sure of it.)\n",
        "    if \"label\" in first and first[\"label\"] is not None:\n",
        "        label = first[\"label\"].item() if isinstance(first[\"label\"], torch.Tensor) else first[\"label\"]\n",
        "        dtype = torch.long if isinstance(label, int) else torch.float\n",
        "        batch[\"labels\"] = torch.tensor([f[\"label\"] for f in features], dtype=dtype)\n",
        "    elif \"label_ids\" in first and first[\"label_ids\"] is not None:\n",
        "        if isinstance(first[\"label_ids\"], torch.Tensor):\n",
        "            batch[\"labels\"] = torch.stack([f[\"label_ids\"] for f in features])\n",
        "        else:\n",
        "            dtype = torch.long if isinstance(first[\"label_ids\"][0], int) else torch.float\n",
        "            batch[\"labels\"] = torch.tensor([f[\"label_ids\"] for f in features], dtype=dtype)\n",
        "\n",
        "    # Handling of all other possible keys.\n",
        "    # Again, we will use the first element to figure out which key/values are not None for this model.\n",
        "    for k, v in first.items():\n",
        "        if k not in (\"label\", \"label_ids\") and v is not None and not isinstance(v, str):\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                batch[k] = torch.stack([f[k] for f in features])\n",
        "            elif isinstance(v, np.ndarray):\n",
        "                batch[k] = torch.from_numpy(np.stack([f[k] for f in features]))\n",
        "            else:\n",
        "                batch[k] = torch.tensor([f[k] for f in features])\n",
        "\n",
        "    return batch"
      ],
      "metadata": {
        "id": "J2s9q0sfHK-0"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "experiment = comet_ml.Experiment(api_key=os.getenv(\"COMET_API_KEY\"), project_name=os.getenv(\"COMET_PROJECT_NAME\"), workspace=os.getenv(\"COMET_WORKSPACE\"))\n",
        "\n",
        "# Define a custom callback to ensure experiment.end() is called\n",
        "class CometCallback(TrainerCallback):\n",
        "    def __init__(self, experiment):\n",
        "        self.experiment = experiment\n",
        "\n",
        "    def on_train_end(self, args, state, control, **kwargs):\n",
        "        self.experiment.end()  # Ends the experiment properly when training ends\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=15,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    save_total_limit=1,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    warmup_steps=63,\n",
        "    learning_rate=2e-5,\n",
        "    #lr_scheduler_type=\"cosine\",\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=None,\n",
        "    dataloader_drop_last=False,\n",
        "    fp16=True, # mixed precision\n",
        "    report_to=[\"comet_ml\"]\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_custom_dataset,\n",
        "    eval_dataset=valid_custom_dataset,\n",
        "    #compute_metrics=compute_metrics,\n",
        "    #compute_loss_func=compute_loss,\n",
        "    #data_collator=torch_weighted_data_collator\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA0D_bgy-pqv",
        "outputId": "ffb8bbf9-966e-4399-ac24-f57d38ce15d5"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : magenta_threshold_9552\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/gonzaq94/ner-classif-bert-doc-level-and-ner-annots-strat-data/d28c65543c834399b48fbdcd6826c9c3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hasNestedParams : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook_url    : https://colab.research.google.com/notebook#fileId=1y_h71Qhq-SJFvUjw-bayMVkvjLKx76TM\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|dispatch_batches             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|even_batches                 : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|gradient_accumulation_kwargs : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|non_blocking                 : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|split_batches                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|use_seedable_sampler         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adafactor                                       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_beta1                                      : 0.9\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_beta2                                      : 0.999\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_epsilon                                    : 1e-08\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|auto_find_batch_size                            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|batch_eval_metrics                              : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|bf16                                            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|bf16_full_eval                                  : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|data_seed                                       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_drop_last                            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_num_workers                          : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_persistent_workers                   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_pin_memory                           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_prefetch_factor                      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_backend                                     : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_broadcast_buffers                           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_bucket_cap_mb                               : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_find_unused_parameters                      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_timeout                                     : 1800\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|debug                                           : []\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|deepspeed                                       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|disable_tqdm                                    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dispatch_batches                                : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_eval                                         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_predict                                      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_train                                        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_accumulation_steps                         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_delay                                      : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_do_concat_batches                          : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_on_start                                   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_steps                                      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_strategy                                   : epoch\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_use_gather_object                          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|evaluation_strategy                             : epoch\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16                                            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_backend                                    : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_full_eval                                  : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_opt_level                                  : O1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp                                            : []\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|min_num_params                      : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla                                 : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla_fsdp_grad_ckpt                  : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla_fsdp_v2                         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_min_num_params                             : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_transformer_layer_cls_to_wrap              : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|full_determinism                                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_accumulation_steps                     : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_checkpointing                          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_checkpointing_kwargs                   : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|greater_is_better                               : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|group_by_length                                 : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|half_precision_backend                          : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_always_push                                 : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_model_id                                    : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_private_repo                                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_strategy                                    : every_save\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_token                                       : <HUB_TOKEN>\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ignore_data_skip                                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_inputs_for_metrics                      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_num_input_tokens_seen                   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_tokens_per_second                       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|jit_mode_eval                                   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|label_names                                     : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|label_smoothing_factor                          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|learning_rate                                   : 2e-05\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|length_column_name                              : length\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|load_best_model_at_end                          : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|local_rank                                      : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_level                                       : passive\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_level_replica                               : warning\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_on_each_node                                : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_dir                                     : ./results/runs/Nov03_18-38-57_b1ad18f762c2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_first_step                              : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_nan_inf_filter                          : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_steps                                   : 500\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_strategy                                : epoch\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|lr_scheduler_kwargs                             : {}\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|lr_scheduler_type                               : linear\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|max_grad_norm                                   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|max_steps                                       : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|metric_for_best_model                           : f1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|mp_parameters                                   : \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|neftune_noise_alpha                             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|no_cuda                                         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|num_train_epochs                                : 15\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim                                           : adamw_torch\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim_args                                      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim_target_modules                            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|output_dir                                      : ./results\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|overwrite_output_dir                            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|past_index                                      : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_device_eval_batch_size                      : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_device_train_batch_size                     : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_gpu_eval_batch_size                         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_gpu_train_batch_size                        : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|prediction_loss_only                            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub                                     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_model_id                            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_organization                        : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_token                               : <PUSH_TO_HUB_TOKEN>\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ray_scope                                       : last\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|remove_unused_columns                           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|report_to                                       : ['comet_ml']\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|restore_callback_states_from_checkpoint         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|resume_from_checkpoint                          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|run_name                                        : ./results\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_on_each_node                               : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_only_model                                 : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_safetensors                                : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_steps                                      : 500\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_strategy                                   : epoch\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_total_limit                                : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|seed                                            : 42\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|skip_memory_metrics                             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|split_batches                                   : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tf32                                            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile                                   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile_backend                           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile_mode                              : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_empty_cache_steps                         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torchdynamo                                     : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tpu_metrics_debug                               : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tpu_num_cores                                   : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_cpu                                         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_ipex                                        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_legacy_prediction_loop                      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_mps_device                                  : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|warmup_ratio                                    : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|warmup_steps                                    : 63\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|weight_decay                                    : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|_name_or_path                                 : \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|add_cross_attention                           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|architectures                                 : ['BertForMaskedLM']\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|attention_probs_dropout_prob                  : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|bad_words_ids                                 : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|begin_suppress_tokens                         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|bos_token_id                                  : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|chunk_size_feed_forward                       : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|classifier_dropout                            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|cross_attention_hidden_size                   : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|decoder_start_token_id                        : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|diversity_penalty                             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|do_sample                                     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|early_stopping                                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|encoder_no_repeat_ngram_size                  : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|eos_token_id                                  : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|exponential_decay_length_penalty              : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|finetuning_task                               : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|forced_bos_token_id                           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|forced_eos_token_id                           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|gradient_checkpointing                        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|hidden_act                                    : gelu\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|hidden_dropout_prob                           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|hidden_size                                   : 768\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|id2label|0                                    : LABEL_0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|id2label|1                                    : LABEL_1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|initializer_range                             : 0.02\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|intermediate_size                             : 3072\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|is_decoder                                    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|is_encoder_decoder                            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|label2id|LABEL_0                              : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|label2id|LABEL_1                              : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|layer_norm_eps                                : 1e-12\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|length_penalty                                : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|max_length                                    : 20\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|max_position_embeddings                       : 512\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|min_length                                    : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|model_type                                    : bert\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|no_repeat_ngram_size                          : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_attention_heads                           : 12\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_beam_groups                               : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_beams                                     : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_hidden_layers                             : 12\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_return_sequences                          : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_sequence_labels                           : 5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_token_labels                              : 9\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_attentions                             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_hidden_states                          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_scores                                 : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|pad_token_id                                  : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|position_embedding_type                       : absolute\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|prefix                                        : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|problem_type                                  : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|pruned_heads                                  : {}\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|remove_invalid_values                         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|repetition_penalty                            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|return_dict                                   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|return_dict_in_generate                       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|sep_token_id                                  : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|seq_loss_weight                               : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|suppress_tokens                               : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|task_specific_params                          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|temperature                                   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tf_legacy_loss                                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tie_encoder_decoder                           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tie_word_embeddings                           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tokenizer_class                               : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|top_k                                         : 50\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|top_p                                         : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|torch_dtype                                   : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|torchscript                                   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|transformers_version                          : 4.44.2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|type_vocab_size                               : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|typical_p                                     : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|use_bfloat16                                  : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|use_cache                                     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|vocab_size                                    : 30522\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/gonzaq94/ner-classif-bert-doc-level-and-ner-annots-strat-data/27fbc49134e244be86f1626a1543aca1\n",
            "\n",
            "PyTorch: setting up devices\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
            "Using auto half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dZuah_E6-re5",
        "outputId": "37fef010-186c-404f-fab1-adcc31834131"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 1,000\n",
            "  Num Epochs = 15\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1,875\n",
            "  Number of trainable parameters = 109,493,006\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m An experiment with the same configuration options is already running and will be reused.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[-1, 9]' is invalid for input of size 10240",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1938\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1939\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2278\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2279\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3317\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3318\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3320\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-f10329887fcc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, token_labels, sequence_labels, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m     65\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                   \u001b[0mactive_token_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                   \u001b[0mactive_token_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                   active_labels_token = torch.where(\n\u001b[1;32m     69\u001b[0m                       \u001b[0mactive_token_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 9]' is invalid for input of size 10240"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "experiment = comet_ml.ExistingExperiment(api_key=os.getenv(\"COMET_API_KEY\"), previous_experiment=\"b5163229a9f4498bb5250bfe8e264c7e\")\n",
        "experiment.log_model(\"BERT-base-doc_classif-1k-stratified-wloss_wsampling-cos_ann\", \"results/checkpoint-336\")\n",
        "experiment.register_model(\"BERT-base-doc_classif-1k-stratified-wloss_wsampling-cos_ann\")"
      ],
      "metadata": {
        "id": "vA5Tk-cqdLuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28684707-2b42-458e-aade-2a1c909e929a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : frightened_apricot_5344\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/gonzaq94/ner-classif-bert-doc-level-annots-strat-data/b5163229a9f4498bb5250bfe8e264c7e\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epoch [31]                   : (1.0, 15.0)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_accuracy [15]           : (0.24660194174757283, 0.8796116504854369)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_f1 [15]                 : (0.3008875445810343, 0.8839729131071746)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_loss [15]               : (0.3039099872112274, 1.524991750717163)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_precision [15]          : (0.6693201569376076, 0.8991127672593024)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_recall [15]             : (0.24660194174757283, 0.8796116504854369)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_runtime [15]            : (3.7182, 4.6998)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_samples_per_second [15] : (219.158, 277.014)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_steps_per_second [15]   : (13.83, 17.481)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     grad_norm [15]               : (0.03937815874814987, 12.573273658752441)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     learning_rate [15]           : (1.3814530889433298e-09, 1.9950307753654016e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [79]                    : (0.002025780500844121, 1.664706826210022)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     total_flos                   : 1973386068480000.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss                   : 0.26133333905821754\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_runtime                : 400.7718\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_samples_per_second     : 37.428\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_steps_per_second       : 1.572\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hasNestedParams : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook_url    : https://colab.research.google.com/notebook#fileId=https%3A%2F%2Fgithub.com%2Fgonzaq94%2FNER-LLM-classification%2Fblob%2Fmain%2Ffine_tune_BERT_doc_level_annots.ipynb\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|dispatch_batches             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|even_batches                 : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|gradient_accumulation_kwargs : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|non_blocking                 : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|split_batches                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|use_seedable_sampler         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adafactor                                       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_beta1                                      : 0.9\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_beta2                                      : 0.999\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_epsilon                                    : 1e-08\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|auto_find_batch_size                            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|batch_eval_metrics                              : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|bf16                                            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|bf16_full_eval                                  : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|data_seed                                       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_drop_last                            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_num_workers                          : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_persistent_workers                   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_pin_memory                           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_prefetch_factor                      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_backend                                     : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_broadcast_buffers                           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_bucket_cap_mb                               : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_find_unused_parameters                      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_timeout                                     : 1800\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|debug                                           : []\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|deepspeed                                       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|disable_tqdm                                    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dispatch_batches                                : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_eval                                         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_predict                                      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_train                                        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_accumulation_steps                         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_delay                                      : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_do_concat_batches                          : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_on_start                                   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_steps                                      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_strategy                                   : epoch\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_use_gather_object                          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|evaluation_strategy                             : epoch\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16                                            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_backend                                    : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_full_eval                                  : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_opt_level                                  : O1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp                                            : []\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|min_num_params                      : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla                                 : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla_fsdp_grad_ckpt                  : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla_fsdp_v2                         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_min_num_params                             : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_transformer_layer_cls_to_wrap              : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|full_determinism                                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_accumulation_steps                     : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_checkpointing                          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_checkpointing_kwargs                   : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|greater_is_better                               : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|group_by_length                                 : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|half_precision_backend                          : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_always_push                                 : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_model_id                                    : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_private_repo                                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_strategy                                    : every_save\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_token                                       : <HUB_TOKEN>\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ignore_data_skip                                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_inputs_for_metrics                      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_num_input_tokens_seen                   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_tokens_per_second                       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|jit_mode_eval                                   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|label_names                                     : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|label_smoothing_factor                          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|learning_rate                                   : 2e-05\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|length_column_name                              : length\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|load_best_model_at_end                          : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|local_rank                                      : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_level                                       : passive\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_level_replica                               : warning\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_on_each_node                                : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_dir                                     : ./results/runs/Nov03_09-32-45_34a5c7980b00\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_first_step                              : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_nan_inf_filter                          : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_steps                                   : 500\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_strategy                                : epoch\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|lr_scheduler_kwargs                             : {}\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|lr_scheduler_type                               : cosine\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|max_grad_norm                                   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|max_steps                                       : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|metric_for_best_model                           : f1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|mp_parameters                                   : \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|neftune_noise_alpha                             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|no_cuda                                         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|num_train_epochs                                : 15\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim                                           : adamw_torch\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim_args                                      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim_target_modules                            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|output_dir                                      : ./results\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|overwrite_output_dir                            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|past_index                                      : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_device_eval_batch_size                      : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_device_train_batch_size                     : 24\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_gpu_eval_batch_size                         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_gpu_train_batch_size                        : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|prediction_loss_only                            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub                                     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_model_id                            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_organization                        : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_token                               : <PUSH_TO_HUB_TOKEN>\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ray_scope                                       : last\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|remove_unused_columns                           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|report_to                                       : ['comet_ml']\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|restore_callback_states_from_checkpoint         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|resume_from_checkpoint                          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|run_name                                        : ./results\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_on_each_node                               : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_only_model                                 : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_safetensors                                : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_steps                                      : 500\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_strategy                                   : epoch\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_total_limit                                : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|seed                                            : 42\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|skip_memory_metrics                             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|split_batches                                   : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tf32                                            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile                                   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile_backend                           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile_mode                              : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_empty_cache_steps                         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torchdynamo                                     : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tpu_metrics_debug                               : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tpu_num_cores                                   : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_cpu                                         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_ipex                                        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_legacy_prediction_loop                      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_mps_device                                  : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|warmup_ratio                                    : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|warmup_steps                                    : 63\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|weight_decay                                    : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|_name_or_path                                 : bert-base-uncased\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|add_cross_attention                           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|architectures                                 : ['BertForMaskedLM']\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|attention_probs_dropout_prob                  : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|bad_words_ids                                 : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|begin_suppress_tokens                         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|bos_token_id                                  : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|chunk_size_feed_forward                       : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|classifier_dropout                            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|cross_attention_hidden_size                   : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|decoder_start_token_id                        : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|diversity_penalty                             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|do_sample                                     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|early_stopping                                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|encoder_no_repeat_ngram_size                  : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|eos_token_id                                  : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|exponential_decay_length_penalty              : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|finetuning_task                               : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|forced_bos_token_id                           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|forced_eos_token_id                           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|gradient_checkpointing                        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|hidden_act                                    : gelu\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|hidden_dropout_prob                           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|hidden_size                                   : 768\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|id2label|0                                    : LABEL_0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|id2label|1                                    : LABEL_1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|id2label|2                                    : LABEL_2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|id2label|3                                    : LABEL_3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|id2label|4                                    : LABEL_4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|initializer_range                             : 0.02\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|intermediate_size                             : 3072\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|is_decoder                                    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|is_encoder_decoder                            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|label2id|LABEL_0                              : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|label2id|LABEL_1                              : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|label2id|LABEL_2                              : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|label2id|LABEL_3                              : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|label2id|LABEL_4                              : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|layer_norm_eps                                : 1e-12\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|length_penalty                                : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|max_length                                    : 20\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|max_position_embeddings                       : 512\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|min_length                                    : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|model_type                                    : bert\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|no_repeat_ngram_size                          : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_attention_heads                           : 12\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_beam_groups                               : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_beams                                     : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_hidden_layers                             : 12\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_return_sequences                          : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_attentions                             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_hidden_states                          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_scores                                 : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|pad_token_id                                  : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|position_embedding_type                       : absolute\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|prefix                                        : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|problem_type                                  : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|pruned_heads                                  : {}\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|remove_invalid_values                         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|repetition_penalty                            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|return_dict                                   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|return_dict_in_generate                       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|sep_token_id                                  : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|suppress_tokens                               : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|task_specific_params                          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|temperature                                   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tf_legacy_loss                                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tie_encoder_decoder                           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tie_word_embeddings                           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tokenizer_class                               : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|top_k                                         : 50\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|top_p                                         : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|torch_dtype                                   : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|torchscript                                   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|transformers_version                          : 4.44.2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|type_vocab_size                               : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|typical_p                                     : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|use_bfloat16                                  : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|use_cache                                     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|vocab_size                                    : 30522\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     asset               : 7 (1.22 GB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/gonzaq94/ner-classif-bert-doc-level-annots-strat-data/b5163229a9f4498bb5250bfe8e264c7e\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate best model"
      ],
      "metadata": {
        "id": "XrFYvnNyYHNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from comet_ml import API\n",
        "\n",
        "api = API(api_key=os.getenv(\"COMET_API_KEY\"))\n",
        "\n",
        "# model name\n",
        "model_name = \"BERT-base-doc_classif-1k-stratified-wloss_wsampling\"\n",
        "\n",
        "#get the Model object\n",
        "model = api.get_model(workspace=os.getenv(\"COMET_WORKSPACE\"), model_name=model_name)\n",
        "\n",
        "# Download a Registry Model:\n",
        "model.download(\"1.0.0\", \"./deploy\", expand=True)"
      ],
      "metadata": {
        "id": "QB0ZoajpdTG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b9281b-7ed3-4a32-ef23-c14a39f36a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Remote Model 'gonzaq94/BERT-base-doc_classif-1k-stratified-wloss_wsampling:1.0.0' download has been started asynchronously.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 14 file(s), remaining 2.45 GB/2.45 GB\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m File './deploy/checkpoint-336/training_args.bin' has been overwritten by asset '1c35cbc477b844b5998f8fd742e9820a' of remote model\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m File './deploy/checkpoint-336/scheduler.pt' has been overwritten by asset '4e36675ca40b48dbb2d1cb5b0182695e' of remote model\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m File './deploy/checkpoint-336/trainer_state.json' has been overwritten by asset '3acd262a0cae466482c69fa6c3a32ae0' of remote model\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m File './deploy/checkpoint-336/scheduler.pt' has been overwritten by asset '532308c9cdf4429088bfadfbf7b62421' of remote model\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m File './deploy/checkpoint-336/config.json' has been overwritten by asset '5edf49a92c5241b7b411f1b5eafd967a' of remote model\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m File './deploy/checkpoint-336/optimizer.pt' has been overwritten by asset '180b842b308f4ddbb349c42a22e6f6f7' of remote model\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m File './deploy/checkpoint-336/optimizer.pt' has been overwritten by asset '72897f55e64048e1b39bf78d0815d334' of remote model\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m File './deploy/checkpoint-336/model.safetensors' has been overwritten by asset '9c13f83d83734f8abddfd98eb74dd9cf' of remote model\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m File './deploy/checkpoint-336/model.safetensors' has been overwritten by asset '6f39046ab22145e491f548b5a848c394' of remote model\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 9 file(s), remaining 1.46 GB/2.45 GB, Throughput 67.53 MB/s, ETA ~23s\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m File './deploy/checkpoint-336/trainer_state.json' has been overwritten by asset 'a47e5046840a4ab6b8e7c694503cb3a4' of remote model\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m File './deploy/checkpoint-336/config.json' has been overwritten by asset 'be474d3eb17744ec99748ebe626e550f' of remote model\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m File './deploy/checkpoint-336/rng_state.pth' has been overwritten by asset 'e56ceaf701e34622b5aac660ab3f36f7' of remote model\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m File './deploy/checkpoint-336/training_args.bin' has been overwritten by asset 'f57cb0e5b9e74328a3525b8dc2f41257' of remote model\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m File './deploy/checkpoint-336/rng_state.pth' has been overwritten by asset 'ffc5b02f083d4cb58b65586d374b914d' of remote model\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 529.95 MB/2.45 GB, Throughput 64.09 MB/s, ETA ~9s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Remote Model 'gonzaq94/BERT-base-doc_classif-1k-stratified-wloss_wsampling:1.0.0' has been successfully downloaded.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Downloaded asset files is in './deploy' folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, class_names):\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Normalized confusion Matrix')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()\n",
        "\n",
        "def compute_metrics_eval(p):\n",
        "    predictions, labels = p\n",
        "    predictions = predictions.argmax(-1)  # Get the predicted class indices\n",
        "    true_predictions = [p for (p, l) in zip(predictions.flatten(), labels.flatten()) if l != -100]\n",
        "    true_labels = [l for l in labels.flatten() if l != -100]\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, true_predictions, average='weighted', zero_division=1 )\n",
        "    acc = accuracy_score(true_labels, true_predictions)\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    conf_matrix = confusion_matrix(true_labels, true_predictions, normalize='true')\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'confusion_matrix': conf_matrix\n",
        "    }\n",
        "\n",
        "\n",
        "class Evaluator:\n",
        "    def __init__(self, model, tokenizer, compute_metrics):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.compute_metrics = compute_metrics\n",
        "\n",
        "    def evaluate(self, eval_dataset, batch_size=16):\n",
        "        trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            compute_metrics=self.compute_metrics,\n",
        "            eval_dataset=eval_dataset,\n",
        "        )\n",
        "        return trainer.evaluate()"
      ],
      "metadata": {
        "id": "EIEhSlXkVAyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_label_dct = {\"World\": 0, \"Sport\": 1, \"Business\": 2, \"Technology\": 3, \"Other\": 4}\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"./deploy/checkpoint-336\", num_labels=len(doc_label_dct))\n"
      ],
      "metadata": {
        "id": "4ifpWVtRWpbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = Evaluator(model, tokenizer, compute_metrics_eval)\n",
        "eval_results = evaluator.evaluate(test_custom_dataset)"
      ],
      "metadata": {
        "id": "pB2auBbxYP1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "88cc49fc-4fab-44a9-f02a-8f3240ff5349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [216/216 00:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m An experiment with the same configuration options is already running and will be reused.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Cannot safely convert array([[9.16317992e-01, 1.25523013e-02, 2.51046025e-02, 0.00000000e+00,\n",
            "        4.60251046e-02],\n",
            "       [1.56372166e-03, 8.98358092e-01, 7.81860829e-04, 0.00000000e+00,\n",
            "        9.92963253e-02],\n",
            "       [5.48245614e-02, 4.38596491e-03, 8.55263158e-01, 4.38596491e-03,\n",
            "        8.11403509e-02],\n",
            "       [0.00000000e+00, 0.00000000e+00, 2.14285714e-01, 5.71428571e-01,\n",
            "        2.14285714e-01],\n",
            "       [7.44027304e-02, 1.21501706e-01, 4.36860068e-02, 1.36518771e-03,\n",
            "        7.59044369e-01]]) object to a scalar value, using its string representation for logging. Resulting string might be invalid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [k for k, v in doc_label_dct.items()]\n",
        "plot_confusion_matrix(eval_results['eval_confusion_matrix'], class_names)"
      ],
      "metadata": {
        "id": "RPr0yd6CYSc_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "outputId": "5c1622c1-d8e9-45b4-82c1-8ea3e2f82b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in eval_results.items():\n",
        "  if key != 'eval_confusion_matrix':\n",
        "    print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmKij6pBX-tk",
        "outputId": "bbd70ada-b341-4960-ec72-19b30d685266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval_loss: 0.5044994354248047\n",
            "eval_model_preparation_time: 0.0035\n",
            "eval_accuracy: 0.8334781349551115\n",
            "eval_f1: 0.8339902590250613\n",
            "eval_precision: 0.8416399874694014\n",
            "eval_recall: 0.8334781349551115\n",
            "eval_runtime: 12.0451\n",
            "eval_samples_per_second: 286.674\n",
            "eval_steps_per_second: 17.933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dS8kKb95XW9O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}